{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb5238-2c07-4fe7-8d84-63048b89359f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dpo\n",
    "# from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "# from peft import LoraConfig\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, TrainingArguments\n",
    "\n",
    "# from trl import DPOTrainer\n",
    "\n",
    "def extract_anthropic_prompt(prompt_and_response, search_term=\"\\n\\nAssistant:\"):\n",
    "    \"\"\"Extract the anthropic prompt from a prompt and response pair.\"\"\"\n",
    "    search_term_idx = prompt_and_response.rfind(search_term)\n",
    "    assert search_term_idx != -1, f\"Prompt and response does not contain '{search_term}'\"\n",
    "    return prompt_and_response[: search_term_idx + len(search_term)]\n",
    "\n",
    "\n",
    "def get_hh(split: str, sanity_check: bool = False, silent: bool = False, cache_dir: str = None) -> Dataset:\n",
    "    \"\"\"Load the Anthropic Helpful-Harmless dataset from Hugging Face and convert it to the necessary format.\n",
    "\n",
    "    The dataset is converted to a dictionary with the following structure:\n",
    "    {\n",
    "        'prompt': List[str],\n",
    "        'chosen': List[str],\n",
    "        'rejected': List[str],\n",
    "    }\n",
    "\n",
    "    Prompts should be structured as follows:\n",
    "      \\n\\nHuman: <prompt>\\n\\nAssistant:\n",
    "    Multiple turns are allowed, but the prompt should always start with \\n\\nHuman: and end with \\n\\nAssistant:.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"Anthropic/hh-rlhf\", split=split, cache_dir=cache_dir)\n",
    "    if sanity_check:\n",
    "        dataset = dataset.select(range(min(len(dataset), 1000)))\n",
    "\n",
    "    def split_prompt_and_responses(sample) -> Dict[str, str]:\n",
    "        prompt = extract_anthropic_prompt(sample[\"chosen\"])\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"chosen\": sample[\"chosen\"][len(prompt) :],\n",
    "            \"rejected\": sample[\"rejected\"][len(prompt) :],\n",
    "        }\n",
    "\n",
    "    return dataset.map(split_prompt_and_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6737de8-e4c0-4865-b86e-3e9a90417890",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "cache_dir = None\n",
    "dataset = load_dataset(\"Anthropic/hh-rlhf\", split=split, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6573a97-32e2-4466-bc1f-9412f4ef59e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from fastchat.model.model_adapter import get_conversation_template\n",
    "\n",
    "def extract_anthropic_prompt(prompt_and_response, search_term=\"\\n\\nAssistant:\"):\n",
    "    \"\"\"Extract the anthropic prompt from a prompt and response pair.\"\"\"\n",
    "    search_term_idx = prompt_and_response.rfind(search_term)\n",
    "    assert search_term_idx != -1, f\"Prompt and response does not contain '{search_term}'\"\n",
    "    return prompt_and_response[: search_term_idx + len(search_term)]\n",
    "\n",
    "class hankang_DPODataset:\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataset_path=\"/data/llm_datasets/Ultrafeedback_binarized.ko.hankang/\",\n",
    "        data_format='chat-orca',\n",
    "        search_term='\\n\\n### Assistant:',\n",
    "        num_train=None,\n",
    "        num_eval=None,\n",
    "    ):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.data_format = data_format\n",
    "        self.search_term = search_term\n",
    "        self.num_train = num_train\n",
    "        self.num_eval = num_eval\n",
    "    \n",
    "    def get_prompt_and_response(self, data):\n",
    "        conv = get_conversation_template(self.data_format)\n",
    "\n",
    "        for idx, _conv in enumerate(data):\n",
    "            role = _conv['role']\n",
    "            content = _conv['content_kr']\n",
    "            if idx % 2 == 0 and role == 'user':\n",
    "                conv.append_message(conv.roles[0], content)\n",
    "            elif idx % 2 == 1 and role == 'assistant':\n",
    "                conv.append_message(conv.roles[1], content)\n",
    "            else:\n",
    "                print(\"Warning: data type invaild\")\n",
    "\n",
    "        if len(conv.messages) == 0:\n",
    "            print(\"Warning: data is empty\")\n",
    "        if len(conv.messages) % 2 != 0:\n",
    "            print(\"Warning: data has weird pair\")\n",
    "\n",
    "        return conv.get_prompt()\n",
    "    \n",
    "    def make_dpo_data_module(self):\n",
    "        def validate_prompt_and_responses(data) -> bool:\n",
    "            try:\n",
    "                prompt_and_response = self.get_prompt_and_response(data['chosen'])\n",
    "                prompt_and_response_rejected = self.get_prompt_and_response(data['rejected'])\n",
    "                prompt = extract_anthropic_prompt(prompt_and_response, self.search_term)\n",
    "                promopt_rejected = extract_anthropic_prompt(prompt_and_response_rejected, self.search_term)\n",
    "            except AssertionError:\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        def split_prompt_and_responses(data) -> Dict[str, str]:\n",
    "            prompt_and_response = self.get_prompt_and_response(data['chosen'])\n",
    "            prompt_and_response_rejected = self.get_prompt_and_response(data['rejected'])\n",
    "            prompt = extract_anthropic_prompt(prompt_and_response, self.search_term)\n",
    "            promopt_rejected = extract_anthropic_prompt(prompt_and_response_rejected, self.search_term)\n",
    "            return {\n",
    "                \"prompt\": prompt,\n",
    "                \"chosen\": prompt_and_response[len(prompt) :],\n",
    "                \"rejected\": prompt_and_response_rejected[len(promopt_rejected) :],\n",
    "            }\n",
    "                             \n",
    "                             \n",
    "        dataset = load_dataset(self.dataset_path)\n",
    "\n",
    "        train_dataset = dataset['train']\n",
    "        eval_dataset = dataset['test']\n",
    "\n",
    "        original_columns = list(train_dataset.features.keys())\n",
    "\n",
    "        if self.num_train is not None:\n",
    "            train_dataset = train_dataset.select(range(min(len(train_dataset), self.num_train)))\n",
    "        if self.num_eval is not None:\n",
    "            eval_dataset = eval_dataset.select(range(min(len(train_dataset), self.num_eval)))\n",
    "\n",
    "        train_dataset = train_dataset.filter(validate_prompt_and_responses)\n",
    "        train_dataset = train_dataset.map(split_prompt_and_responses, remove_columns=original_columns)\n",
    "\n",
    "        eval_dataset = eval_dataset.filter(validate_prompt_and_responses)\n",
    "        eval_dataset = eval_dataset.map(split_prompt_and_responses, remove_columns=original_columns)\n",
    "\n",
    "        return dict(train_dataset=train_dataset, eval_dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773658d4-5976-453e-b91b-d281a76e7393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ados/anaconda3/envs/fastchat_train_2023dec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Filter: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61752/61752 [00:06<00:00, 9603.56 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61734/61734 [00:12<00:00, 5061.69 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1999/1999 [00:00<00:00, 9628.81 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1999/1999 [00:00<00:00, 4990.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from fastchat.train.data_modules.dpo_dataset import hankang_DPODataset\n",
    "\n",
    "dpo_dataset = hankang_DPODataset()\n",
    "dpo_datamodule = dpo_dataset.make_dpo_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe192c6-a6f7-47b8-aef8-fb70add915cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ados/anaconda3/envs/fastchat_train_2023dec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573a423-9af0-44ef-9e75-512030ddb84f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import DPOTrainer\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c76e3-9609-47cf-a66a-0558f661a947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DPOTrainer("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982fe04a-b449-4320-9f64-c354c423ec0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "dir(transformers.TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b0b830-1fea-48c0-b96b-513fe633e016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = 853/46302 \n",
    "#16:08:08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad325b0a-721a-4bec-afd5-828d1fd307b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = 16/ (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5c7a23-a399-4b08-b142-fab9273b00ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.21722222222222"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "159182/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0feb4a-59f8-4f32-8a1b-c43f9a9f2f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastchat_train_2023dec",
   "language": "python",
   "name": "fastchat_train_2023dec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
