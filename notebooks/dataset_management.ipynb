{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb5238-2c07-4fe7-8d84-63048b89359f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dpo\n",
    "# from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "# from peft import LoraConfig\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, TrainingArguments\n",
    "\n",
    "# from trl import DPOTrainer\n",
    "\n",
    "def extract_anthropic_prompt(prompt_and_response, search_term=\"\\n\\nAssistant:\"):\n",
    "    \"\"\"Extract the anthropic prompt from a prompt and response pair.\"\"\"\n",
    "    search_term_idx = prompt_and_response.rfind(search_term)\n",
    "    assert search_term_idx != -1, f\"Prompt and response does not contain '{search_term}'\"\n",
    "    return prompt_and_response[: search_term_idx + len(search_term)]\n",
    "\n",
    "\n",
    "def get_hh(split: str, sanity_check: bool = False, silent: bool = False, cache_dir: str = None) -> Dataset:\n",
    "    \"\"\"Load the Anthropic Helpful-Harmless dataset from Hugging Face and convert it to the necessary format.\n",
    "\n",
    "    The dataset is converted to a dictionary with the following structure:\n",
    "    {\n",
    "        'prompt': List[str],\n",
    "        'chosen': List[str],\n",
    "        'rejected': List[str],\n",
    "    }\n",
    "\n",
    "    Prompts should be structured as follows:\n",
    "      \\n\\nHuman: <prompt>\\n\\nAssistant:\n",
    "    Multiple turns are allowed, but the prompt should always start with \\n\\nHuman: and end with \\n\\nAssistant:.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"Anthropic/hh-rlhf\", split=split, cache_dir=cache_dir)\n",
    "    if sanity_check:\n",
    "        dataset = dataset.select(range(min(len(dataset), 1000)))\n",
    "\n",
    "    def split_prompt_and_responses(sample) -> Dict[str, str]:\n",
    "        prompt = extract_anthropic_prompt(sample[\"chosen\"])\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"chosen\": sample[\"chosen\"][len(prompt) :],\n",
    "            \"rejected\": sample[\"rejected\"][len(prompt) :],\n",
    "        }\n",
    "\n",
    "    return dataset.map(split_prompt_and_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6737de8-e4c0-4865-b86e-3e9a90417890",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "cache_dir = None\n",
    "dataset = load_dataset(\"Anthropic/hh-rlhf\", split=split, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6573a97-32e2-4466-bc1f-9412f4ef59e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from fastchat.model.model_adapter import get_conversation_template\n",
    "\n",
    "def extract_anthropic_prompt(prompt_and_response, search_term=\"\\n\\nAssistant:\"):\n",
    "    \"\"\"Extract the anthropic prompt from a prompt and response pair.\"\"\"\n",
    "    search_term_idx = prompt_and_response.rfind(search_term)\n",
    "    assert search_term_idx != -1, f\"Prompt and response does not contain '{search_term}'\"\n",
    "    return prompt_and_response[: search_term_idx + len(search_term)]\n",
    "\n",
    "class hankang_DPODataset:\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataset_path=\"/data/llm_datasets/Ultrafeedback_binarized.ko.hankang/\",\n",
    "        data_format='chat-orca',\n",
    "        search_term='\\n\\n### Assistant:',\n",
    "        num_train=None,\n",
    "        num_eval=None,\n",
    "    ):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.data_format = data_format\n",
    "        self.search_term = search_term\n",
    "        self.num_train = num_train\n",
    "        self.num_eval = num_eval\n",
    "    \n",
    "    def get_prompt_and_response(self, data):\n",
    "        conv = get_conversation_template(self.data_format)\n",
    "\n",
    "        for idx, _conv in enumerate(data):\n",
    "            role = _conv['role']\n",
    "            content = _conv['content_kr']\n",
    "            if idx % 2 == 0 and role == 'user':\n",
    "                conv.append_message(conv.roles[0], content)\n",
    "            elif idx % 2 == 1 and role == 'assistant':\n",
    "                conv.append_message(conv.roles[1], content)\n",
    "            else:\n",
    "                print(\"Warning: data type invaild\")\n",
    "\n",
    "        if len(conv.messages) == 0:\n",
    "            print(\"Warning: data is empty\")\n",
    "        if len(conv.messages) % 2 != 0:\n",
    "            print(\"Warning: data has weird pair\")\n",
    "\n",
    "        return conv.get_prompt()\n",
    "    \n",
    "    def make_dpo_data_module(self):\n",
    "        def validate_prompt_and_responses(data) -> bool:\n",
    "            try:\n",
    "                prompt_and_response = self.get_prompt_and_response(data['chosen'])\n",
    "                prompt_and_response_rejected = self.get_prompt_and_response(data['rejected'])\n",
    "                prompt = extract_anthropic_prompt(prompt_and_response, self.search_term)\n",
    "                promopt_rejected = extract_anthropic_prompt(prompt_and_response_rejected, self.search_term)\n",
    "            except AssertionError:\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        def split_prompt_and_responses(data) -> Dict[str, str]:\n",
    "            prompt_and_response = self.get_prompt_and_response(data['chosen'])\n",
    "            prompt_and_response_rejected = self.get_prompt_and_response(data['rejected'])\n",
    "            prompt = extract_anthropic_prompt(prompt_and_response, self.search_term)\n",
    "            promopt_rejected = extract_anthropic_prompt(prompt_and_response_rejected, self.search_term)\n",
    "            return {\n",
    "                \"prompt\": prompt,\n",
    "                \"chosen\": prompt_and_response[len(prompt) :],\n",
    "                \"rejected\": prompt_and_response_rejected[len(promopt_rejected) :],\n",
    "            }\n",
    "                             \n",
    "                             \n",
    "        dataset = load_dataset(self.dataset_path)\n",
    "\n",
    "        train_dataset = dataset['train']\n",
    "        eval_dataset = dataset['test']\n",
    "\n",
    "        original_columns = list(train_dataset.features.keys())\n",
    "\n",
    "        if self.num_train is not None:\n",
    "            train_dataset = train_dataset.select(range(min(len(train_dataset), self.num_train)))\n",
    "        if self.num_eval is not None:\n",
    "            eval_dataset = eval_dataset.select(range(min(len(train_dataset), self.num_eval)))\n",
    "\n",
    "        train_dataset = train_dataset.filter(validate_prompt_and_responses)\n",
    "        train_dataset = train_dataset.map(split_prompt_and_responses, remove_columns=original_columns)\n",
    "\n",
    "        eval_dataset = eval_dataset.filter(validate_prompt_and_responses)\n",
    "        eval_dataset = eval_dataset.map(split_prompt_and_responses, remove_columns=original_columns)\n",
    "\n",
    "        return dict(train_dataset=train_dataset, eval_dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773658d4-5976-453e-b91b-d281a76e7393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ados/anaconda3/envs/fastchat_train_2023dec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastchat.train.data_modules.dpo_dataset import hankang_DPODataset\n",
    "\n",
    "dpo_dataset = hankang_DPODataset()\n",
    "dpo_datamodule = dpo_dataset.make_dpo_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed009ce-d6b9-4a1a-8986-b96f7c01ba11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset = dpo_datamodule['eval_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516f9fd-e885-4042-b93e-da390d6cd509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93bbd6-8df1-4e94-a30c-4d21e009fc86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastchat.conversation import (\n",
    "    SeparatorStyle,\n",
    ")\n",
    "conv = get_conversation_template('chat-orca')\n",
    "system_message = conv.system_message\n",
    "sep_style = conv.sep_style\n",
    "sep = conv.sep\n",
    "prompt_user, prompt_bot = conv.roles\n",
    "\n",
    "len_sep_style = 0\n",
    "if sep_style == SeparatorStyle.ADD_COLON_TWO:\n",
    "    len_sep_style = 1\n",
    "\n",
    "len_front = len(system_message) + len(sep) + len(prompt_user) + len_sep_style + 1\n",
    "len_rear = len(sep) + len(prompt_bot) + len_sep_style\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1179a912-3a2a-459a-bd93-88c2f87195d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import random\n",
    "from fastchat.modules.embedder_adapter import Embedder, get_embedder\n",
    "from fastchat.conversation import (\n",
    "    SeparatorStyle,\n",
    ")\n",
    "import copy\n",
    "\n",
    "def dedup_dpo_datamodule(dpo_datamodule, target_text_len=100, n_results=100, threshold = 0.6):\n",
    "    # prepare datamodule\n",
    "    train_dataset = dpo_datamodule['train_dataset']\n",
    "    eval_dataset = dpo_datamodule['eval_dataset']\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    conv = get_conversation_template('chat-orca')\n",
    "    system_message = conv.system_message\n",
    "    sep_style = conv.sep_style\n",
    "    sep = conv.sep\n",
    "    prompt_user, prompt_bot = conv.roles\n",
    "\n",
    "    len_sep_style = 0\n",
    "    if sep_style == SeparatorStyle.ADD_COLON_TWO:\n",
    "        len_sep_style = 1\n",
    "\n",
    "    len_front = len(system_message) + len(sep) + len(prompt_user) + len_sep_style + 1\n",
    "    len_rear = len(sep) + len(prompt_bot) + len_sep_style\n",
    "    def filter_question(data):\n",
    "        return { \n",
    "            **data,\n",
    "            'prompt': data['prompt'][len_front:-len_rear][:target_text_len]\n",
    "        }\n",
    "\n",
    "    train_dataset = train_dataset.map(filter_question)\n",
    "    eval_dataset = eval_dataset.map(filter_question)\n",
    "    \n",
    "    for _data_id, dataset in enumerate([train_dataset, eval_dataset]):\n",
    "        chroma_client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "        embedder = get_embedder(\"ddobokki/klue-roberta-base-nli-sts-ko-en\")\n",
    "        collection = chroma_client.create_collection(name=\"context\", embedding_function=embedder.embed, metadata={\"hnsw:space\": \"cosine\"})\n",
    "        ids = []\n",
    "        # add\n",
    "        texts = dataset['prompt']\n",
    "        last_id = -1\n",
    "        new_ids = [f\"id{i+last_id+1}\" for i in range(len(texts))]\n",
    "        ids += new_ids\n",
    "        collection.add(documents=texts, ids=new_ids)\n",
    "        \n",
    "        query_ids = copy.deepcopy(new_ids)\n",
    "        selected_ids = []\n",
    "        duplicated_ids = []\n",
    "        \n",
    "        while query_ids:\n",
    "            current_id = random.choice(query_ids)\n",
    "            selected_ids.append(current_id)\n",
    "            search_strings = [texts[int(current_id[2:])]]\n",
    "            result = collection.query(query_texts=search_strings, n_results=min(n_results, len(query_ids)), include=['distances']) #'documents'\n",
    "\n",
    "            search_ids = result['ids'][0]\n",
    "            distances = result['distances'][0]\n",
    "            remove_ids = []\n",
    "            for idx in range(len(search_ids)):\n",
    "                sid = search_ids[idx]\n",
    "                dist = distances[idx]\n",
    "                if dist < threshold:\n",
    "                    remove_ids.append(sid)\n",
    "\n",
    "            for rid in remove_ids:\n",
    "                if rid in query_ids:\n",
    "                    query_ids.remove(rid)\n",
    "            duplicated_ids += remove_ids\n",
    "            collection.delete(ids=remove_ids)\n",
    "\n",
    "            print(len(new_ids), len(selected_ids), len(remove_ids), collection.count(), len(query_ids), len(duplicated_ids), '\\t\\t\\t\\t\\t', end='\\r')\n",
    "        \n",
    "        if _data_id == 0:\n",
    "            print('finished dedup train data:', len(new_ids), len(selected_ids), len(remove_ids), collection.count(), len(query_ids), len(duplicated_ids))\n",
    "        else:\n",
    "            print('finished dedup eval data:', len(new_ids), len(selected_ids), len(remove_ids), collection.count(), len(query_ids), len(duplicated_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670ebf9c-079e-4e75-abff-ce148cb0b0f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import random\n",
    "from fastchat.modules.embedder_adapter import Embedder, get_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f7a1f5-2557-4821-8675-1a35d7edceb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "embedder = get_embedder(\"ddobokki/klue-roberta-base-nli-sts-ko-en\")\n",
    "collection = chroma_client.create_collection(name=\"context\", embedding_function=embedder.embed, metadata={\"hnsw:space\": \"cosine\"})\n",
    "ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c94b2f-4ebe-4816-b9b6-1995699d5e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len_system = len('### System:\\nThis is a system prompt, please behave and help the user.')\n",
    "len_user = len('\\n\\n### User: ')\n",
    "len_bot = len('\\n\\n\\n### Assistant:')\n",
    "text_len = 100\n",
    "def remove_system(data):\n",
    "    return { \n",
    "        **data,\n",
    "        'prompt': data['prompt'][len_system + len_user:-len_bot][:text_len]\n",
    "    }\n",
    "\n",
    "eval_dataset = eval_dataset.map(remove_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72adf750-a6b3-458d-ab4e-6574d2bafeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rejected': ' 히비스쿠스 빌라는 산림 관리 목재, 풍성한 야자 나무 기둥, 알랑알랑 풀 초가지 지붕, 고급 물 양치류 강 모시 직물 및 원목 가구와 천연 석벽과 수생 동물을 포함한 천연 소재를 사용하여 지어졌습니다. 이 빌라는 보르네오 해안의 멋진 위치에 자리 잡고 있으며 백사장과 개인 동굴, 맑은 바다와 야자수 등 짧은 산책 거리 내에 있습니다. 개인 집사가 24시간 서비스를 제공하며 숙박 기간 동안 모든 필요를 충족시켜 드립니다.\\n\\n이 빌라는 2에이커 이상의 개인 열대 정원이 있으며, 대형 개인 천연 대리석 수영장이 있어 공간과 프라이버시를 보장하고 고립된 느낌을 줍니다. 게스트는 매일 청소 서비스, 세탁 서비스, 완비된 주방, 수영장, 패들 풀, 열대 정원 및 선 베드에서 이용할 수 있습니다. 또한 이 빌라에서는 무료 Wi-Fi 접속과 홈 시네마 및 게임 룸을 포함한 다양한 엔터테인먼트 옵션도 제공합니다.\\n\\n히비스쿠스 빌라는 멋진 자연 환경에서 고급스럽고 친밀한 휴식 경험을 원하는 분들에게 완벽한 선택입니다. 풀장에서 휴식을 취하거나 해변에서 일광욕을 즐기거나 현지 지역을 탐험하고 싶으시다면 빌라의 위치와 시설이 보르네오 여행의 이상적인 베이스가 될 것입니다.\\n</s>',\n",
       " 'prompt': '히비스쿠스 빌라의 건축에 어떤 자재가 사용되며, 게스트가 이용할 수 있는 시설과 서비스는 무엇인가요?\\n에르세테는 다음과 같이 제공됩니다: 히비스쿠스 빌라는 보르네오 해안의 뛰어난 ',\n",
       " 'chosen': ' 히비스쿠스 빌라는 보르네오 해안에 위치한 고급스럽고 프라이빗한 빌라입니다. 이 빌라는 개인 집사가 서비스를 제공하며 2에이커 이상의 개인 열대 정원이 있습니다. 이 숙소는 아름다운 정원을 갖추고 있으며, 대형 천연 암반 수영장이 공간과 프라이버시를 제공합니다. 이 빌라는 숲을 가꾸는 원목, 풍성한 야자수 기둥, 알랑알랑 풀 초가지붕 지붕, 고급 수생 양치류 강모초 직조 및 목재 가구와 자연 석벽 및 물 기능을 포함한 천연 소재로 지어졌습니다.\\n\\n히비스쿠스 빌라는 매일 청소 서비스, 세탁 서비스, 완비된 주방, 수영장, 패들 풀, 열대 정원 및 선 베드와 같은 훌륭한 시설을 이용할 수 있습니다. 또한 전용 해변에 접근할 수 있어 휴식을 취하고 긴장을 풀기에 완벽한 곳입니다.\\n\\n히비스쿠스 빌라의 게스트는 수영, 일광욕, 낚시, 스노클링, 다이빙 등 다양한 액티비티를 즐길 수 있습니다. 또한 다양한 레스토랑과 상점이 가까워 현지 지역을 탐험하기에 완벽한 곳입니다.\\n\\n고급스럽고 편안한 휴가를 원하신다면 히비스쿠스 빌라가 완벽한 곳입니다. 아름다운 위치, 아름다운 정원, 뛰어난 시설을 갖춘 히비스쿠스 빌라는 잊지 못할 경험을 선사할 것입니다.\\n\\n히비스쿠스 빌라의 건축에 사용된 자재 목록입니다:\\n\\n* 관리된 산림용 목재\\n* 풍성한 코코넛 나무 기둥\\n* 알랑알랑 풀 초가지 지붕\\n* 고급스러운 수생 자수정 강변 잔디와 목재 가구\\n* 천연 석벽과 물의 특징\\n\\n히비스쿠스 빌라의 게스트가 이용할 수 있는 시설 및 서비스 목록입니다:\\n\\n* 매일 청소 서비스\\n* 세탁부 서비스\\n* 완비된 주방\\n* 수영장\\n* 수영장\\n* 열대 정원\\n* 선 눕기\\n* 전용 해변 액세스*\\n수영, 일광욕, 낚시, 스노클링, 다이빙 등 다양한 액티비티를 즐길 수 있습니다.\\n* 다양한 레스토랑과 상점과의 근거리 위치\\n</s>'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478181de-5864-4430-b7e2-1e5855f33a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add\n",
    "texts = eval_dataset['prompt']\n",
    "\n",
    "last_id = -1\n",
    "new_ids = [f\"id{i+last_id+1}\" for i in range(len(texts))]\n",
    "ids += new_ids\n",
    "collection.add(documents=texts, ids=new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec5ac75e-7817-4172-a7e3-0010429be6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: 스페인어 문장이 주어집니다. 여러분의 임무는 스페인어 문장을 갈리시아어로 번역하는 것입니다.\\n\\n입력:\\n아니요, 저는 완벽한 평등에 대해 말하고 있지 않습니다. 민주주의가 발달한 부유한 시장에서 존재하는 것에 대해 이야기하고 있습니다.\\n\\n출력:\\n저는 완벽에 가까운 말을 하고 있습니다. 부유한 시장에서 존재하는 것에 대해 말합니다.\\n\\n\\n입력:\\n늑대와 비슷한 생명체부터 시작하여 말테스로 마무리합니다.\\n\\n출력:\\n늑대처럼 생긴 생물을 만들고 몰트의 맛을 더했습니다.\\n\\n\\n입력:\\n그래서 이것은 해초 과일입니다. 이렇게 불립니다.\\n\\n출력:\\n\\n\\n\\n### Assistant:'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['prompt'][0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e23ef68-5c9f-4123-933a-86b27dbf7963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6084772-84c6-43fd-b3c7-cb5831904e59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "query_ids = copy.deepcopy(new_ids)\n",
    "\n",
    "n_results = 100\n",
    "threshold = 0.6\n",
    "\n",
    "selected_ids = []\n",
    "duplicated_ids = []\n",
    "# while query_ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e37383e-8ee6-4a01-9bf7-5110ba7789be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 877 1 0 0 1999 \t\t\t\t\t\t\t\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "while query_ids:\n",
    "    \n",
    "    current_id = random.choice(query_ids)\n",
    "    selected_ids.append(current_id)\n",
    "    search_strings = [texts[int(current_id[2:])]]\n",
    "    if collection.count() == 0:\n",
    "        print(\"Warning: collection is empty. Forced break\")\n",
    "        break\n",
    "    result = collection.query(query_texts=search_strings, n_results=min(n_results, len(query_ids)), include=['distances']) #'documents'\n",
    "\n",
    "    search_ids = result['ids'][0]\n",
    "    distances = result['distances'][0]\n",
    "    remove_ids = []\n",
    "    for idx in range(len(search_ids)):\n",
    "        sid = search_ids[idx]\n",
    "        dist = distances[idx]\n",
    "        if dist < threshold:\n",
    "            remove_ids.append(sid)\n",
    "    \n",
    "    for rid in remove_ids:\n",
    "        if rid in query_ids:\n",
    "            query_ids.remove(rid)\n",
    "    duplicated_ids += remove_ids\n",
    "    collection.delete(ids=remove_ids)\n",
    "    \n",
    "    print(len(new_ids), len(selected_ids), len(remove_ids), collection.count(), len(query_ids), len(duplicated_ids), '\\t\\t\\t\\t\\t', end='\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "daddab51-7bfa-420a-abd2-dbbb8ec920a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id53806', 'id44222', 'id42888']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ids[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "01fe625b-9928-4c52-96c7-64803a74b334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61734 17110 0 0 10057 51677 \t\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "print(len(new_ids), len(selected_ids), len(remove_ids), collection.count(), len(query_ids), len(duplicated_ids), '\\t\\t\\t\\t\\t', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "98d8b55d-26f1-453e-a27d-80671f8aa38f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61993"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(selected_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "cb44d670-e3d1-40f2-add7-34bd51936b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사람들이 유니폼을 입은 축구 선수가 모래밭에서 발을 차는 모습을 지켜봅니다.\\n질문과 답변은 아래에 있습니다.\\n\"검은 옷을 입은 검은 머리의 소년이 모래밭에서 축구공을 찬다.\"라는 '"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d3245d-e411-455b-8e60-8a09a5cb5b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_ids = [int(sid[2:]) for sid in set(selected_ids)]\n",
    "\n",
    "eval_dataset = dpo_datamodule['eval_dataset']\n",
    "eval_dataset = eval_dataset.select(selected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6c7f4f9-b397-460f-b4aa-b45e6a5700a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['rejected', 'prompt', 'chosen'],\n",
       "    num_rows: 877\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "6d91ae88-db55-4a2d-9ceb-c57843bc6ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36750, 36750)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_ids), collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2d770dc-f6c7-4d92-a726-69f8d9165fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.93ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5736347"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.to_json(f\"dpo-eval.jsonl\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9f49ad21-b696-4767-8d15-b006ce304dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id0']"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "2d87423f-17de-41d9-959a-d1749c988743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_ids= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f4b735fa-ec03-4ef7-8203-55575361ebe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    collection.delete(ids=new_ids[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d8ad0adb-2943-46a2-9221-f3381edc6719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 100 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    }
   ],
   "source": [
    "result = collection.query(query_texts=search_strings, n_results=n_results, include=['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "7fb4a462-ac99-45bb-bbfe-aa635dfeb36b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 100 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    }
   ],
   "source": [
    "result = collection.query(query_texts='먼저 작업에 대한 정의가 주어지고, 그 다음에 작업의 입력이 주어집니다.\\nGujarati로 된 텍스트가 주어집니다. 구자라트어에서 파잔비어로 번역합니다. 번역은 원문 문장에 정보를', n_results=100, include=['documents', 'distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "793b0869-570d-49b5-861f-fd54bec46ddd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 126 ms, sys: 195 ms, total: 321 ms\n",
      "Wall time: 381 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collection.delete(ids=remove_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5a52b4a7-405b-478a-886a-306a224879a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'id26896' in remove_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "0ef8b06d-ee39-41c6-841d-26d0ad1683f7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['스페인어 문장이 주어집니다. 여러분의 임무는 스페인어 문장을 갈리시아어로 번역하는 것입니다.\\n\\n입력:\\n아니요, 저는 완벽한 평등에 대해 말하고 있지 않습니다. 민주주의가 발달한 부'],\n",
       " [0.7323936223983765])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['documents'][0], result['distances'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06be969-d446-4633-9a14-bb87082767b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result['ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "737f7496-705f-4a37-a46d-b21954387af3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['먼저 작업에 대한 정의가 주어지고, 그 다음에 작업의 입력이 주어집니다.\\nGujarati로 된 텍스트가 주어집니다. 구자라트어에서 파잔비어로 번역합니다. 번역은 원문 문장에 정보를']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab973584-30f7-41ed-a6cf-af5ba9f164b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import DPOTrainer\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c76e3-9609-47cf-a66a-0558f661a947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DPOTrainer("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982fe04a-b449-4320-9f64-c354c423ec0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "dir(transformers.TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b0b830-1fea-48c0-b96b-513fe633e016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = 853/46302 \n",
    "#16:08:08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad325b0a-721a-4bec-afd5-828d1fd307b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = 16/ (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5c7a23-a399-4b08-b142-fab9273b00ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.21722222222222"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "159182/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0feb4a-59f8-4f32-8a1b-c43f9a9f2f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ados/anaconda3/envs/fastchat_train_2023dec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('dpo_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ebdef31-2b40-49e9-a256-4a21e4517d88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['rejected', 'prompt', 'chosen'],\n",
       "        num_rows: 10316\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['rejected', 'prompt', 'chosen'],\n",
       "        num_rows: 877\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc04e5e-947e-4b37-89ac-c0790f03d3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rejected': ' 물론이죠! 이것은 흥미로운 개념입니다. 다음은 창의적인 프로세스를 통해 새로운 커피 아이디어를 창출하는 동시에 흥미롭고 재미있게 만드는 데 도움이 될 수 있는 창의적인 프로세스입니다:\\n\\n1. 커피 테마 브레인스토밍 세션:\\n커피 애호가부터 요리 전문가에 이르기까지 다양한 배경의 개인들로 그룹을 구성하세요. 이를 통해 커피 아이디어에 대한 폭넓은 관점을 확보할 수 있습니다.\\n2. 아이스 브레이커:\\n모두에게 좋아하는 커피 이야기나 특별한 커피와 관련된 기억을 공유하도록 요청하여 세션을 시작하세요. 창의적인 분위기를 조성하는 재미있는 방법입니다.\\n3. 그룹 활동:\\n참가자들을 소그룹으로 나누고 기본 커피 재료(커피 원두, 우유, 설탕 등)와 일반적인 커피 추출 방법(에스프레소, 카푸치노, 라테 등) 목록을 제공합니다.\\n4. 창의적 마인드 매핑:\\n각 그룹은 각 재료 또는 방법에 대한 다양한 커피 아이디어와 레시피로 마인드 맵을 생성해야 합니다. 각 그룹 구성원이 자유롭게 아이디어를 공유하고 마인드 맵에 적극적으로 참여하도록 장려하세요.\\n5. 그룹 프레젠테이션:\\n정의된 시간이 지나면 각 그룹이 자신의 아이디어를 더 큰 그룹에 발표합니다. 이렇게 하면 모든 사람이 생성된 다양한 아이디어를 보고 대화와 창의성을 자극하는 데 도움이 됩니다.\\n6. 그룹 협업:\\n각 그룹은 각 그룹에서 가장 좋아하는 아이디어 세 가지를 선택하고, 가장 인기 있고 혁신적인 아이디어라고 생각하는 상위 아이디어에 투표해야 합니다. 이렇게 하면 모든 그룹의 관심사를 바탕으로 최선의 아이디어가 선정되고 정당화되며 뒷받침됩니다.\\n7. 실험 및 개선:\\n각 그룹이 레시피와 준비 과정에 모두 기여하여 우승 아이디어를 더욱 발전시킬 수 있습니다. 각 그룹은 음료를 만들어 맛에 대한 피드백을 제공하고 완벽한 레시피를 완성할 때까지 다듬을 수 있습니다.\\n8. 최종 시음 및 선택:\\n최종 제품을 모두 맛보고 어떤 맛을 좋아하는지 확인하세요. 이를 통해 최종 제품의 개선에 도움이 됩니다.\\n9. 구현:\\n최종 제품이 완성되고 모두가 결과에 만족하면 구현할 수 있습니다. 그런 다음 그룹은 함께 협력하여 새로운 커피 아이디어를 현실로 만들 수 있습니다.\\n\\n이 프로세스는 새로운 커피 아이디어를 창출할 뿐만 아니라 재미있고 협력적인 방식으로 사람들을 함께 모을 수 있습니다. 그 결과 모두가 참여하여 독특하고 창의적인 새로운 커피 아이디어가 탄생합니다.\\n</s>',\n",
       " 'prompt': '### System:\\nThis is a system prompt, please behave and help the user.\\n\\n### User: 재미있으면서도 새로운 커피 아이디어를 창출하는 데 도움이 되는 창의적인 프로세스를 개발할 수 있도록 도와주시겠어요?\\n\\n\\n### Assistant:',\n",
       " 'chosen': ' 물론이죠! 커피에 대한 혁신적인 아이디어를 브레인스토밍하는 데 도움이 되는 재미있고 흥미로운 창의적 프로세스를 소개합니다:\\n\\n1. 영감 단계:\\n커피와 그 기원에 관한 다큐멘터리, TV 프로그램 또는 영화를 시청하세요.\\n- 현지 커피숍을 방문하여 커피를 어떻게 추출하고 제공하는지 확인하세요.\\n커피, 커피의 역사, 다양한 추출 방법에 관한 기사를 읽고 책을 읽습니다.\\n- 바리스타 및 커피 애호가와 대화하여 인사이트와 개인 취향을 파악하세요.\\n\\n2. 아이디어 창출:\\n- 친구들과 함께 \\'커피 시음\\' 세션을 준비하세요: 다양한 종류의 커피(예: 로스팅 방법, 추출 방법, 지역 등)를 준비하여 함께 맛보세요. 각 커피에 대해 좋아하거나 싫어하는 점을 토론하고 메모해 보세요.\\n- 단어 연상 게임을 즐겨보세요: 커피와 관련된 무작위 단어를 적고, 그 단어와 연관된 창의적인 커피 아이디어를 생각해 보세요.\\n- \"커피 포틀럭\"을 주최하세요: 친구들을 초대하여 좋아하는 커피나 창의적인 커피 칵테일을 가져오고, 그 레시피와 그 레시피를 만든 이야기를 공유하세요.\\n\\n3. 컨셉 개발:\\n- 생성된 아이디어 중에서 어떤 것이 가장 마음에 드는지 확인하세요.\\n- 선택한 아이디어에 대해 더 심층적으로 조사하고 이를 개선할 수 있는 방법을 찾습니다.\\n- 커피 창작물을 시각화하는 데 도움이 되는 개념에 대한 스케치 또는 설명을 작성합니다.\\n\\n4. 프로토타이핑:\\n- 레시피와 추출 방법을 실험하여 선택한 개념을 더 발전시키세요.\\n- 재료, 양, 단계 및 결과를 기록하여 실험을 문서화합니다.\\n\\n5. 피드백 및 반복:\\n- 커피 프로토타입을 친구들과 공유하고 그들의 의견과 제안을 요청하세요.\\n- 받은 피드백을 바탕으로 커피 콘셉트를 수정하고 개선합니다.\\n- 최종 커피 창작물이 만족스러질 때까지 아이디어를 계속 다듬으세요.\\n\\n6. 프레젠테이션:\\n- 친구, 가족 또는 동료에게 새로운 커피 아이디어를 소개하는 \\'커피 쇼케이스\\' 파티를 개최하세요.\\n- 레시피 북, 블로그 또는 웹사이트를 만들어 더 많은 사람들과 커피 창작물을 공유하세요.\\n- 지역 커피숍과 아이디어를 공유하세요. 메뉴에 창작물을 도입하는 데 관심이 있을 수 있습니다.\\n\\n이 창의적인 과정을 통해 재미와 혁신을 촉진하는 것임을 기억하세요. 위험을 감수하고 실험을 수용하며 커피에 대한 열정을 따라야 합니다. 여정을 즐기세요!\\n</s>'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5693f0a-ab8c-4f2a-bc1f-d39c055b90f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastchat_train_2023dec",
   "language": "python",
   "name": "fastchat_train_2023dec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
