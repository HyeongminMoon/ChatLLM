{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "74ff3f73-a3f6-430f-8645-20d3f4990461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# api_server_url = \"http://localhost:21122\"\n",
    "api_server_url = \"https://allsecure.co.kr/llm\"\n",
    "# api_server_url = \"http://localhost:41001\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbdf51-652b-4106-9b42-2a0283efd3d9",
   "metadata": {},
   "source": [
    "# 1. Controller API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd859ec5-900b-46c9-96a5-a83b7aee2ef8",
   "metadata": {},
   "source": [
    "### GET /list_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d0b746f6-05f9-4b2e-8e84-a844ab810c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'models': [{'name': 'OLLM-Large', 'model_name': 'OLLM-Large_2023.11.20', 'description': '선택하신 모델은 OLLM-Large에요. OLLM-Large는 보다 질높은 답변을 하며, 다른 기술과 연동하여 긴 맥락으로부터 답변하는 상황에 유리해요'}]}\n"
     ]
    }
   ],
   "source": [
    "ret = requests.get(api_server_url + \"/list_models\")\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e7137-781d-48e3-a7bc-96db61972ed4",
   "metadata": {},
   "source": [
    "### GET /refresh_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "03458df9-352e-4f16-99ea-89833f55b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = requests.get(api_server_url + \"/refresh_all_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00665250-cf02-4a0e-9a7f-13739e827e8f",
   "metadata": {},
   "source": [
    "### GET /get_random_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7029b02e-1ce5-480d-a6f4-68687bca8112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uuid': '48a5a28aaf554537bcf9eaa8ebc64739'}\n"
     ]
    }
   ],
   "source": [
    "ret = requests.get(api_server_url + \"/get_random_uuid\")\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9a268-9056-4d2a-b626-bca22bab7db4",
   "metadata": {},
   "source": [
    "### (deprecated) {controller_address}/get_worker_address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a1eb9-4c2b-4c6a-a3a1-8cb3233a39d9",
   "metadata": {},
   "source": [
    "model_name = output_json['models'][1]\n",
    "print(\"model_name:\", model_name)\n",
    "\n",
    "input_json = {\n",
    "    \"model\": model_name\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    controller_url + \"/get_worker_address\", \n",
    "    json=input_json\n",
    ")\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c808422-d4cf-47d5-bc1b-8a6fac87e47e",
   "metadata": {},
   "source": [
    "# 2. Worker API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d06ab-38c7-4d93-aaa1-c4c744e639ac",
   "metadata": {},
   "source": [
    "### POST /model_details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f480d40b-c57d-4a5c-852e-f992450e23f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_length': 4096}\n"
     ]
    }
   ],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"OLLM-Small_2024.01.16\",\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/model_details\",\n",
    "    json=input_json,\n",
    ")\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1180905-8dbc-412c-b4aa-46be1c38fc16",
   "metadata": {},
   "source": [
    "### POST /worker_get_conv_template  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "870084f9-8215-439f-9bc7-87312de6037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv': {'name': 'chat-orca', 'system_template': '{system_message}', 'system_message': '### System:\\nYou are an AI assistant, please behave and help the user.', 'roles': ['### User', '### Assistant'], 'messages': [], 'offset': 0, 'sep_style': 2, 'sep': '\\n\\n', 'sep2': '</s>', 'stop_str': ['</s>'], 'stop_token_ids': None, 'tasks': {'retrieval': '### System:\\nYou are an AI assistant, please behave and help the user.\\nDate:{date}\\nYour reply should be based on the context below.\\n\\nContext:{instruction}', 'instruct': '### System:\\nYou are an AI assistant, please behave and help the user. Your reply should be based on the context below.\\n\\nContext:{instruction}', 'system_instruct': '### System:\\n{system}', 'correction': '', 'summarization': '### System:\\nYou are an AI assistant, Summarize below sentences.', 'enkotranslation': '### System:\\nYou are an AI translator, who knows every language and how to translate one language to another. convert english sentences to korean sentences. do not write explanations.', 'koentranslation': '### System:\\nYou are an AI translator, who knows every language and how to translate one language to another. convert korean sentences to english sentences. do not write explanations.'}}}\n"
     ]
    }
   ],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"OLLM-Small_2024.01.16\",\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_get_conv_template\",\n",
    "    json=input_json,\n",
    ")\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb64af-60a4-4731-9334-c29bf056552d",
   "metadata": {},
   "source": [
    "### POST /count_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66ada64e-2a49-4ab6-b084-42b1b04cd32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 966, 'error_code': 0}\n"
     ]
    }
   ],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"OLLM-Small_2024.01.16\",\n",
    "    # \"prompt\": \"### System:\\nThis is a system prompt, please behave and help the user.\\n\\n### User: NFC는 무엇의 약자입니까?\\n\\n### Assistant:\"\n",
    "    \"prompt\": \"\"\"### System:\n",
    "You are an AI assistant, please behave and help the user. Your name is OLLM(오름) by Ados(주식회사아도스), OLLM stands for On-premise LLM.\n",
    "### User: I want you to act as a Table of Contents extractor. I will speak to you questions. I want you to reply with Table of Contents extracted from the questions. You must keep original text. do not write explanations. My first command is ```\n",
    "〈목 차〉\n",
    "제1장 서 론 ·································1\n",
    "1.1 연구배경 ..............1\n",
    "1.2 연구목적 ................2\n",
    "제2장 연구의 범위 ··························3\n",
    "2.1 VOC의 정의 및 중요성 .............3\n",
    "2.2 관련 연구 및 차별성 .................3\n",
    "제3장 자본이동론성 ·····························4\n",
    "3.1 과거 자본론의 수집과 분류 ................5\n",
    "3.2 자본이동론의 주제어 선정 .....................8\n",
    "3.3 가중치의 설정 ........................... 13\n",
    "3.4 온라인 자본 탐지 기법의 알고리즘 ........ 16\n",
    "제4장 LO CB코인의 사회경제적 지위 ························18\n",
    "4.1 실험에 사용된 데이터 ................ 21\n",
    "4.2 실험 대상 및 결과 ...................... 22\n",
    "제5장 새로운 방식의 보증개척 시스템-LO CB코인 23\n",
    "제6장 맺음말 ·························24\n",
    "참고문헌 ··············\n",
    "\n",
    "차트 목차\n",
    "<차트 1> 디지털 데이터 생성량 예측 추이표 ..............2\n",
    "<차트 2> 전처리 파라미터 ............... 17\n",
    "<차트 3> CB코인 사회지위 변화도 ........... 18\n",
    "```\n",
    "\n",
    "### Assistant: 〈목 차〉\n",
    "제1장 서 론\n",
    "1.1 연구배경\n",
    "1.2 연구목적\n",
    "제2장 연구의 범위\n",
    "2.1 VOC의 정의 및 중요성\n",
    "2.2 관련 연구 및 차별성\n",
    "제3장 자본이동론성\n",
    "3.1 과거 자본론의 수집과 분류\n",
    "3.2 자본이동론의 주제어 선정\n",
    "3.3 가중치의 설정\n",
    "3.4 온라인 자본 탐지 기법의 알고리즘\n",
    "제4장 LO CB코인의 사회경제적 지위\n",
    "4.1 실험에 사용된 데이터\n",
    "4.2 실험 대상 및 결과\n",
    "제5장 새로운 방식의 보증개척 시스템-LO CB코인\n",
    "제6장 맺음말\n",
    "참고문헌</s>\"\"\",\n",
    "}\n",
    "\n",
    "ret = requests.post(api_server_url + \"/count_token\", json=input_json)\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3ed9d9-075a-44fd-8ff7-1e447ab46fc9",
   "metadata": {},
   "source": [
    "### POST /worker_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "414d532b-ab14-41d1-8714-9135b377167e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"### 영어:\\nQ: What command do I use to find the size of all the files (recursively) in a Linux or Mac OS X directory?\\nA: The BSD version of ```du``` used in OS X reports size with 512-byte blocks -- the sizes are essentially rounded up to the next 512-byte value. This tells you the space on disk, which is larger than the amount of data. If you have a lot of small files, the difference can be large.\\nHere's an example.\\nThis is the value with regular ```du```. It's in 512-byte blocks:\\n```$ du -s\\n248   .\\n```\\nThe ```-h``` flag results in a more readable number, in kilobytes. As expected, it's half the number of 512-byte blocks:\\n```$ du -hs\\n124K  .\\n```\\nFinally, you can use ```find``` and ```awk``` to give you the sum of actual bytes in the files. This is kind of slow, but it works:\\n```$ find . -type f -exec ls -l {} \\\\; | awk '{sum += $5} END {print sum}'\\n60527\\n```\\nThis value matches exactly the number reported by Finder's Get Info window. (There are no weird forks or xattrs in this set of files.) It's significantly smaller than the value reported by ```du```.\\nHere's how it works: it gets a list of all the files, and passes them to ```ls -l```; then ```awk``` is used to count up the bytes. The ```-type f``` flag is there so that only files (and not directories) get sent to ```ls```. Without that flag, it'll also send directory names to ```ls```, and each file will be listed twice : once as an individual file, and once as an item in the directory.\\nThe GNU version of ```du``` can give values in actual bytes instead of blocks. It's unfortunate that the BSD version of ```du``` is not as flexible.\\n### 한국어:\\nQ: Linux 또는 Mac OS X 디렉터리에서 모든 파일의 크기를 재귀적으로 찾으려면 어떤 명령을 사용해야 하나요?\\nA: OS X에서 사용되는 BSD 버전의 ```du```를 사용하면 512바이트 블록 단위로 크기를 보고하며, 크기는 기본적으로 다음 512바이트 값으로 반올림됩니다. 이를 통해 디스크 공간의 크기를 확인할 수 있으며, 이 크기는 데이터의 양보다 큽니다. 작은 파일이 많은 경우 차이가 클 수 있습니다.\\n다음은 예시입니다.\\n이것은 일반 ```du```를 사용한 값입니다. 512바이트 블록 단위로 표시됩니다:\\n```$ du -s\\n248 .\\n```\\n```-h``` 플래그를 사용하면 킬로바이트 단위로 더 읽기 쉬운 숫자가 표시됩니다. 예상대로 512바이트 블록의 절반에 해당합니다:\\n```$ du -hs\\n124K .\\n```\\n마지막으로, ```find```와 ```awk```를 사용하여 파일에 있는 실제 바이트의 합계를 확인할 수 있습니다. 이것은 약간 느리지만 작동합니다:\\n```$ find . -type f -exec ls -l {} \\\\; | awk '{sum += $5} END {print sum}'\\n60527\\n```\\n이 값은 Finder의 정보 화면에 보고된 값과 정확히 일치합니다. (이 파일 세트에는 이상한 포크나 xattr이 없습니다.) 이 값은 ```du```가 보고한 값보다 훨씬 작습니다.\\n이 작동 방식은 모든 파일 목록을 가져와서 ```ls -l```로 전달한 다음 ```awk```를 사용하여 바이트를 계산하는 것입니다. ```-type f``` 플래그가 있기 때문에 디렉터리(및 디렉터리가 아닌 파일)만 ```ls```로 전송됩니다. 이 플래그가 없으면 디렉터리도 ```ls```로 전송되고 각 파일은 개별 파일로 한 번, 디렉터리 항목으로 한 번 나열됩니다.\\n```du```의 GNU 버전은 블록 대신 실제 바이트 단위로 값을 제공할 수 있습니다. BSD 버전의 ```du```는 유연성이 없어 안타까운 점입니다.\\n\", 'error_code': 0, 'usage': {'prompt_tokens': 473, 'completion_tokens': 477, 'total_tokens': 950}, 'cumulative_logprob': [-51.49804361909628], 'finish_reason': 'stop'}\n"
     ]
    }
   ],
   "source": [
    "dummy = \"\"\"Q: What command do I use to find the size of all the files (recursively) in a Linux or Mac OS X directory?\\nA: The BSD version of ```du``` used in OS X reports size with 512-byte blocks -- the sizes are essentially rounded up to the next 512-byte value. This tells you the space on disk, which is larger than the amount of data. If you have a lot of small files, the difference can be large.\\nHere's an example.\\nThis is the value with regular ```du```. It's in 512-byte blocks:\\n```$ du -s\\n248   .\\n```\\nThe ```-h``` flag results in a more readable number, in kilobytes. As expected, it's half the number of 512-byte blocks:\\n```$ du -hs\\n124K  .\\n```\\nFinally, you can use ```find``` and ```awk``` to give you the sum of actual bytes in the files. This is kind of slow, but it works:\\n```$ find . -type f -exec ls -l {} \\\\; | awk '{sum += $5} END {print sum}'\\n60527\\n```\\nThis value matches exactly the number reported by Finder's Get Info window. (There are no weird forks or xattrs in this set of files.) It's significantly smaller than the value reported by ```du```.\\nHere's how it works: it gets a list of all the files, and passes them to ```ls -l```; then ```awk``` is used to count up the bytes. The ```-type f``` flag is there so that only files (and not directories) get sent to ```ls```. Without that flag, it'll also send directory names to ```ls```, and each file will be listed twice : once as an individual file, and once as an item in the directory.\\nThe GNU version of ```du``` can give values in actual bytes instead of blocks. It's unfortunate that the BSD version of ```du``` is not as flexible.\"\"\"\n",
    "prompt = f\"### 영어:\\n{dummy}\\n### 한국어:\\n\"\n",
    "input_json = {\n",
    "    \"model_name\": \"Gugugo-koen-7B-V1.1\",\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.8,\n",
    "    # \"session_id\": 3,\n",
    "    \"max_new_tokens\": 4096,\n",
    "    \"stop\": [\"</끝>\", \"###\"],\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_generate\",\n",
    "    json=input_json,\n",
    ")\n",
    "\n",
    "output_json = ret.json()\n",
    "# print(output_json)\n",
    "output_json['text'][len(prompt):].rstrip('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded4212-0df3-4dba-86b2-a15d8e1cdc87",
   "metadata": {},
   "source": [
    "### POST /worker_generate_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8a3bfe58-922c-40a9-a14a-65c4da611e4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [목차(Table of Contents)]\n",
      "\n",
      "1. 서론\n",
      "2. 연구 배경\n",
      "2.1 빅 데이터(Big Data)\n",
      "2.2 VOC(Voice of Customer)\n",
      "2.3 온라인 긴급 게시물 실시간 탐지\n",
      "3. 연구 목적\n",
      "4. 연구 방법\n",
      "4.1 데이터 수집\n",
      "4.2 데이터 전처리\n",
      "4.3 텍스트 마이닝\n",
      "4.4 기계 학습\n",
      "4.5 실시간 탐지 시스템\n",
      "5. 결과\n",
      "6. 토론\n",
      "7. 결론\n",
      "8. 참고 문헌\n",
      "\n",
      "[dotted line, page number, 제목(title), content, explanation, summary, predicted] 없음."
     ]
    }
   ],
   "source": [
    "# input_json = {\n",
    "#     \"model_name\": \"MingAI-70B-chat-orca_v0.42_2_dpo-GPTQ\",\n",
    "#     \"prompt\": \"### System:\\nThis is a system prompt, please behave and help the user.\\n\\n### User: react hello world\\n\\n### Assistant: 반응 프로젝트에서 \\\"Hello World\\\"를 표시하려면 다음 단계를 따르십시오.\\n1. 새로운 React 응용 프로그램 생성 :\\n먼저 새로운 React 응용 프로그램을 만들어야합니다.\\n 다음 명령을 실행하여 새로운 React 앱을 만듭니다.\\n```\\nNPX Create-React-App My-App\\n```\\n이 명령은 새로운 폴더`My-App '에서 새로운 React 프로젝트를 만듭니다.\\n2. 구성 요소 만들기 :\\n이제 앱의 루트 구성 요소를 만들어야합니다.\\n 터미널에서 다음 명령을 실행하여 새 구성 요소를 만듭니다.\\n```\\nCD My-App\\nNPX React-S 생성 구성 요소 환경 적 응용 프로그램\\n```\\n이 명령은`src` 디렉토리에`myapp.js`라는 새 파���일을 생성합니다.\\n3. 구성 요소 업데이트 :\\n`myapp.js` 파일을 열고 다음 코드를 추가하십시오.\\n```JS\\n'React'에서 React React React;\\n함수 myapp () {\\n   반환 (\\n     <h1> 안녕하세요, 세계! </h1>\\n   );\\n}\\n수출 기본 MyApp;\\n```\\n이 코드는 \\\"Hello, World!\\\"텍스트를 표시하는 간단한 구성 요소를 만듭니다.\\n4. 구성 요소 렌더링 :\\n이제 앱의 기본 구성 요소를 렌더링해야합니다.\\n `src/index.js` 파일을 열고 코드를 업데이트하십시오.\\n```JS\\n'React'에서 React React React;\\n'./myapp'에서 myapp 가져 오기;\\n기능 실행 () {\\n   반환 (\\n     <MyApp />\\n   );\\n}\\n기본 기능 내보내기;\\n```\\n5. 앱 실행 :\\n마지막으로 앱을 실행해보세요.\\n```\\nNPX 시작\\n```\\n이렇게하면 웹 브라우저에서 응용 프로그램을 실행하는 데 사용할 수있는 개발 서버가 시작됩니다.\\n 응용 프로그램을 열고 브라우저에서 \\\"Hello, World!\\\"텍스트를 표시해야합니다.\\n번역 번역\\n반응 반응 프로젝트 프로젝트에서에서 \\\"hello world\\\"를 표시하려면하려면 다음\",\n",
    "#     \"max_new_tokens\": 1024,\n",
    "#     \"temperature\": 0.7,\n",
    "#     \"top_p\": 0.8,\n",
    "#     \"session_id\": 3,\n",
    "#     \"repetition_penalty\": 1.7,\n",
    "# }\n",
    "user_input = \"\"\"\n",
    "변화될 것이며, 데이터 량 기준은 산업분야에 따라 상대적이다.’ 라고 정\n",
    "의 하였다[4].\n",
    "이 데이터들의 활용은 개별적이고, 즉각적이며, 다면적인 검토를 거\n",
    "친 부가가치를 제공해야 한다. 이 관점에서 빅 데이터는 피드백 대상과\n",
    "실시간성 이라는 두 방향에서 바라볼 필요가 있다. 우선 피드백 대상은\n",
    "데이터를 처리하고 분석하여 얻은 가치(Value)의 피드백 대상이 개별적\n",
    "인 유저인지 아니면 서비스 이용자 전체인지 여부이다. 그 다음의 실시\n",
    "간성은 과거에서 부터 누적되어 왔던 데이터를 분석하여 처리결과를 반\n",
    "환해주는 과거 축적 형인지 아니면 실시간으로 생성되는 데이터들을 분\n",
    "석하여 결과를 반환해주는 실시간 형인지의 여부이다[16]. 초기의 데이\n",
    "터 분석은 과거 축적데이터를 분석하여 계열전체에 피드백을 하는 연구\n",
    "가 대부분 이었지만, 실시간으로 쏟아져 나오는 다양한 출처의 데이터\n",
    "증가와 함께 최근에는 실시간으로 데이터를 분석하여 개별적으로 피드백\n",
    "을 제공하는 연구들이 이루어지고 있다.\n",
    "과거 축적 형\n",
    "(피드백 오래 걸림)\n",
    "실시간 형\n",
    "(즉시 피드백 가능)\n",
    "계열전체에\n",
    "피드백\n",
    "소매업 진열대의\n",
    "상품 배열 최적화\n",
    "방범 카메라 영상의\n",
    "실시간 자동 이상탐지\n",
    "개별적으로\n",
    "피드백\n",
    "전자상거래 사이트의\n",
    "개인별 상품추천\n",
    "VISA 카드의 사용자\n",
    "부정패턴 실시간 탐지\n",
    "[표 2] 피드백 대상과 실시간성\n",
    "- 5 -\n",
    "최근 온라인 이용자의 급격한 증가와 함께 늘어나는 데이터들을 실\n",
    "시간으로 감지(Real Time Sensing)하는 방법들이 다양한 산업 분야에서\n",
    "활용되고 있다.\n",
    "코카콜라(Coca-Cola)는 전 세계 여러 나라의 트위터 이용자들이\n",
    "온라인으로 작성하는 글들을 실시간으로 분석하여, 코카콜라에 대한 부\n",
    "정적인 단어(Keyword)가 증가하는 국가나 지역을 대상으로 집중적인\n",
    "홍보를 실시한다. 코카콜라의 트위터 분석은 영어, 중국어, 일본어, 한국\n",
    "어, 아랍어 등 세계 각 나라의 다양한 언어로 분석되고 있으며, 분석되\n",
    "어진 정보는 각 나라의 코카콜라 자회사로 제공된다.\n",
    "메디시스(MedISys)는 전 세계의 인터넷 문서들을 자동으로 검색하\n",
    "고, 문서 내부의 단어(Keyword)들을 분석하여 공중보건과 관련된 질병\n",
    "이 발생할 것으로 예측되는 지역에 대해 알림을 준다. 메디시스는 43개\n",
    "국의 언어를 분석하며, 1400여개의 뉴스 포털에서 하루 5만개의 정도의\n",
    "기사들을 분석하고 있다.\n",
    "구글(Google)은 독감 증상이 있는 사람들이 늘어나면 독감과 관련\n",
    "된 단어(Keyword)의 검색들이 늘어나는 통계를 기초로 하여, 시간 및\n",
    "지역별 독감 유행 정보를 제공하고 있다. 미국 보건당국은 예보는 일주\n",
    "일 단위로 정보를 알려주지만, 구글은 매일 정보를 알려주기 때문에 보\n",
    "건당국보다 더 빠르게 독감 유행의 징후를 감지하고, 대처할 수 있도록\n",
    "지원한다[12]. 구글은 2008년 2월 미국질병통제센터(CDC)가 Atlanta\n",
    "- 6 -\n",
    "주 정부의 독감 발생을 예보한 것보다, 2주 더 빨리 독감 발생을 예보한\n",
    "바가 있다[13].\n",
    "국내에서는 스마트 폰 출시 전에 소비자들이 해당 스마트폰에 대해\n",
    "어떤 의견들을 가지고 있는지를 댓글 분석을 통해 분석하고, 듀얼 코어\n",
    "로 인해 배터리 시간이 짧을 것이라는 부정적 정보를 미리 파악하여 마\n",
    "케팅 커뮤니케이션에 활용하기도 하였다[18].\n",
    "과거 20년에서 25년 동안 기업들은 활용이 가능한 정보의 약 5%만\n",
    "을 의사결정에 활용해왔다[17]. 빅 데이터의 분석은 많다(Big), 적다\n",
    "(Small) 라는 데이터 규모의 이야기에서 끝나는 것이 아니라, 다양한 정\n",
    "형, 비정형, 반정형 데이터들 속에서 데이터의 패턴을 찾아내고, 그 패턴\n",
    "의 규칙을 어떻게 처리해서 가치(Value)있는 통찰력(Insight)를 얻어낼\n",
    "수 있는가 하는 것을 포함하고 있어야 한다. 즉, 빅 데이터란 큰 규모\n",
    "(Big Volume)만을 의미하기 보다는 ‘큰 가치(Big Value)를 얻을 수 있\n",
    "는 규모’ 라는 상대적인 개념으로 받아들여야 하며, 빅 데이터의 가치\n",
    "(Value)는 패턴을 찾아내고 분석하는 능력과 그 결과로 얻어진 통찰력\n",
    "(Insight)으로 데이터를 처리하는 능력에 달려 있다고 할 수 있다.\n",
    "1.2 연구목적\n",
    "VOC(Voice of Customer)의 활용은 기업의 고객중심 경영에 매우\n",
    "- 7 -\n",
    "중요한 역할을 하며, 그 중 긴급한 VOC 게시물을 신속하게 확인하고 처\n",
    "리하는 것은 기업의 수익과 직접적이고도 밀접한 관련이 있다. 하지만\n",
    "온라인 상담 게시판 및 상품평 게시판을 통해 파악되는 게시물은 운영자\n",
    "가 해당 게시물을 읽고 상황을 파악하기까지 많은 시간을 필요로 하게\n",
    "된다. 보통 50여명 규모의 기업의 운영하는 온라인 컨텐츠 제공업체의\n",
    "경우 고객 서비스 팀에 접수된 게시물은 고객이 온라인에 글을 작성 한\n",
    "후 평균 1시간 이후에 고객이 작성한 게시물을 읽어보게 되며, 고객이\n",
    "많이 몰리는 시간대에는 2-3시간 이후에 고객이 올린 상담 게시물을 읽\n",
    "고 상황을 파악하게 된다. 또한 상품평란에 작성된 고객의 코멘트는 1일\n",
    "이 훨씬 지난 이후에 파악하게 되는 경우도 있다.\n",
    "본 논문에서는 기업의 온라인 웹페이지에서 작성되는 게시물의 긴급\n",
    "성 여부를 실시간으로 파악해 긴급 게시물일 경우 운영자에게 바로 알림\n",
    "을 주어 빠르게 대처할 수 있도록 하여, 시스템 운용 프로세스를 향상시\n",
    "킬 수 있도록 하는 텍스트 마이닝을 이용한 온라인 긴급 게시물 실시간\n",
    "탐지 기법을 제안한다.\n",
    "이를 위해 먼저 과거 축적된 VOC 게시물 데이터 중 긴급 게시물과\n",
    "비긴급 게시물을 분류 한 후, 긴급 게시물 데이터들에서 긴급 게시물의\n",
    "주제어를 찾아낸다. 그리고 긴급 게시물 데이터와 비긴급 게시물 데이터\n",
    "에서 각각 긴급 게시물 주제어를 서술하는 서술어를 모두 추출한다. 그\n",
    "리고 동일한 서술어로 서술되어지는 긴급 게시물의 주제어를 그룹화 한\n",
    "\"\"\"\n",
    "\n",
    "instruct = (\n",
    "    \"I want you to act as a Table of Contents extractor. \"\n",
    "    \"I will speak to you questions. \"\n",
    "    \"I want you to reply only with [목차(Table of Contents)] part extracted from the questions. \"\n",
    "    \"You must keep original text. Do not change original text.\"\n",
    "    \"And you must not involve [dotted line, page number, 제목(title), content, explanation, summary, predicted]. \"\n",
    "    \"do not write explanations. My first command is \"\n",
    ")\n",
    "prompt = f\"\"\"### System:\n",
    "You are an AI assistant, please behave and help the user.\n",
    "### User: {instruct}```\n",
    "{user_input}\n",
    "...\n",
    "```\n",
    "\n",
    "### Assistant:\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "input_json = {\n",
    "    \"model_name\": \"OLLM-Small_2024.01.16\", #\"OLLM-Large_2023.11.20\", # , #\"DIE_10.7b_v0.1_ep2\",\"DIE-MoE-10.7Bx4_v8_gpt_ep3\"\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.8,\n",
    "    # \"session_id\": 3,\n",
    "    \"max_new_tokens\": 4096,\n",
    "    # \"stop\": [\"</끝>\", \"###\"],\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_generate_stream\",\n",
    "    json=input_json,\n",
    "    stream=True,\n",
    "    # timeout=200,\n",
    ")\n",
    "\n",
    "past_len = len(input_json[\"prompt\"])\n",
    "for chunk in ret.iter_lines(decode_unicode=False, delimiter=b\"\\0\"):\n",
    "    if chunk:\n",
    "        data = json.loads(chunk.decode())\n",
    "        print(data[\"text\"][past_len:], sep=\"\", end=\"\")\n",
    "        past_len = len(data[\"text\"])\n",
    "\n",
    "# for chunk in ret.iter_lines(decode_unicode=False, delimiter=b\"\\0\"):\n",
    "#     if chunk:\n",
    "#         data = json.loads(chunk.decode())\n",
    "#         # print(data[\"text\"][past_len:], sep=\"\", end=\"\")\n",
    "#         # past_len = len(data[\"text\"])\n",
    "\n",
    "# result = json.loads(chunk.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "abf676f4-ae6d-4802-b5af-6b8e238ca30e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### 영어:\\nQ: What command do I use to find the size of all the files (recursively) in a Linux or Mac OS X directory?\\nA: The BSD version of ```du``` used in OS X reports size with 512-byte blocks -- the sizes are essentially rounded up to the next 512-byte value. This tells you the space on disk, which is larger than the amount of data. If you have a lot of small files, the difference can be large.\\nHere's an example.\\nThis is the value with regular ```du```. It's in 512-byte blocks:\\n```$ du -s\\n248   .\\n```\\nThe ```-h``` flag results in a more readable number, in kilobytes. As expected, it's half the number of 512-byte blocks:\\n```$ du -hs\\n124K  .\\n```\\nFinally, you can use ```find``` and ```awk``` to give you the sum of actual bytes in the files. This is kind of slow, but it works:\\n```$ find . -type f -exec ls -l {} \\\\; | awk '{sum += $5} END {print sum}'\\n60527\\n```\\nThis value matches exactly the number reported by Finder's Get Info window. (There are no weird forks or xattrs in this set of files.) It's significantly smaller than the value reported by ```du```.\\nHere's how it works: it gets a list of all the files, and passes them to ```ls -l```; then ```awk``` is used to count up the bytes. The ```-type f``` flag is there so that only files (and not directories) get sent to ```ls```. Without that flag, it'll also send directory names to ```ls```, and each file will be listed twice : once as an individual file, and once as an item in the directory.\\nThe GNU version of ```du``` can give values in actual bytes instead of blocks. It's unfortunate that the BSD version of ```du``` is not as flexible.\\n### 한국어:\\nQ: Linux 또는 Mac OS X 디렉터리에서 모든 파일의 크기를 (재귀적으로) 찾으려면 어떤 명령을 사용해야 하나요?\\nA: OS X에서 사용되는 BSD 버전의 ```du```는 512바이트 블록 단위로 크기를 보고하며, 크기는 기본적으로 다음 512바이트 값으로 반올림됩니다. 이는 디스크의 공간으로, 데이터의 양보다 더 큽니다. 작은 파일이 많은 경우 차이가 클 수 있습니다.\\n다음은 예제입니다.\\n이것은 일반적으로 ```du```. 512바이트 블록 단위로 표시됩니다:\\n```$ du -s\\n248 .\\n```\\ndu -h``` 플래그를 사용하면 킬로바이트 단위의 더 읽기 쉬운 값이 표시됩니다. 예상대로 512바이트 블록의 절반에 해당합니다:\\n```$ du -hs\\n124K .\\n```\\n마지막으로 ```find``` 및 ```awk```를 사용하여 파일에서 실제 바이트의 합계를 가져올 수 있습니다. 이것은 다소 느리지만 작동합니다:\\n```\\n$ find . -type f -exec ls -l {} \\\\; | awk '{sum += $5} END {print sum}'\\n60527\\n```\\n이 값은 Finder의 정보 창에 표시되는 값과 정확히 일치합니다. (이 파일 세트에는 이상한 커널이나 xattr이 없습니다). 이 값은 ```du```에서 보고된 값보다 훨씬 작습니다.\\n이것은 어떻게 작동합니까? 모든 파일 목록을 가져와서 ```ls -l```로 전달한 다음 ```awk```가 바이트를 계산하는 데 사용됩니다. ```type f``` 플래그가 있기 때문에 ```ls```에 파일만 전달됩니다. 이 플래그가 없으면 디렉터리 이름도 ```ls``로 전송되며, 각 파일은 개별 파일로 한 번, 디렉터리의 항목으로 한 번씩 나열됩니다.\\ndu```의 BSD 버전은 블록이 아닌 실제 바이트 단위로 값을 제공합니다. 안타깝게도 ```du```의 BSD 버전은 유연하지 않습니다.\\n\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8685063-99fd-49e5-9b6b-bc3399b10993",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node.js 애플리케이션에서 파일을 수신하려면 Express 프레임워크를 사용하여 간단한 웹 서버를 만들 수 있습니다. 다음 예제에서는 `express` 및 `multer` 라이브러리를 사용하여 파일 업로드를 수신하는 방법을 보여줍니다.\n",
      "\n",
      "1. 먼저 npm을 사용하여 필요한 종속성을 설치합니다:```bash\n",
      "npm init -y\n",
      "npm install express multer\n",
      "```\n",
      "\n",
      "2. 새 JavaScript 파일을 생성하고 다음 코드를 붙여넣습니다(예: `app.js`).```javascript\n",
      "const express = require('express');\n",
      "const multer = require('multer');\n",
      "\n",
      "const app = express();\n",
      "const port = 3000;\n",
      "\n",
      "// Configure multer storage settings\n",
      "const storage = multer.diskStorage({\n",
      "  destination: (req, file, cb) => {\n",
      "    cb(null, 'uploads/');\n",
      "  },\n",
      "  filename: (req, file, cb) => {\n",
      "    cb(null, `${file.fieldname}-${Date.now()}${getExtension(file.mimetype)}`);\n",
      "  },\n",
      "});\n",
      "\n",
      "const upload = multer({ storage });\n",
      "\n",
      "function getExtension(mimetype) {\n",
      "  const parts = mimetype.split('/');\n",
      "  return parts[parts.length - 1];\n",
      "}\n",
      "\n",
      "// ROUTES\n",
      "app.post('/upload', upload.single('file'), (req, res) => {\n",
      "  res.send(`File received: ${req.file.filename}`);\n",
      "});\n",
      "\n",
      "// Start the server\n",
      "app.listen(port, () => {\n",
      "  console.log(`Server is running at http://localhost:${port}`);\n",
      "});\n",
      "```\n",
      "\n",
      "\n",
      "이 코드는 포트 3000에서 수신 대기하고 파일 업로드를 위한 단일 경로(`/upload`)를 가진 간단한 Express 서버를 설정합니다. 파일은 'uploads/' 폴더에 저장됩니다. app.js` 파일과 같은 디렉터리에 'uploads/' 폴더를 생성했는지 확인하세요.\n",
      "\n",
      "3. 서버를 실행합니다:```bash\n",
      "node app.js\n",
      "```\n",
      "\n",
      "4. Postman 또는 CURL과 같은 도구를 사용하여 파일 업로드를 테스트합니다:```bash\n",
      "curl -X POST -H \"Content-Type: multipart/form-data\" -F \"file=@/path/to/yourfile.txt\" \"http://localhost:3000/upload\"\n",
      "```\n",
      "\n",
      "\n",
      "\"경로/대상/파일.txt\"를 업로드하려는 파일의 경로로 바꿉니다.\n",
      "\n",
      "이제 서버는 파일을 수신하여 '업로드/' 폴더에 저장하고 업로드된 파일의 이름으로 메시지를 반환해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Node.js 애플리케이션에서 파일을 수신하려면 Express 프레임워크를 사용하여 간단한 웹 서버를 만들 수 있습니다. 다음 예제에서는 `express` 및 `multer` 라이브러리를 사용하여 파일 업로드를 수신하는 방법을 보여줍니다.\\n\\n1. 먼저 npm을 사용하여 필요한 종속성을 설치합니다:```bash\\nnpm init -y\\nnpm install express multer\\n```\\n\\n2. 새 JavaScript 파일을 생성하고 다음 코드를 붙여넣습니다(예: `app.js`).```javascript\\nconst express = require(\\'express\\');\\nconst multer = require(\\'multer\\');\\n\\nconst app = express();\\nconst port = 3000;\\n\\n// Configure multer storage settings\\nconst storage = multer.diskStorage({\\n  destination: (req, file, cb) => {\\n    cb(null, \\'uploads/\\');\\n  },\\n  filename: (req, file, cb) => {\\n    cb(null, `${file.fieldname}-${Date.now()}${getExtension(file.mimetype)}`);\\n  },\\n});\\n\\nconst upload = multer({ storage });\\n\\nfunction getExtension(mimetype) {\\n  const parts = mimetype.split(\\'/\\');\\n  return parts[parts.length - 1];\\n}\\n\\n// ROUTES\\napp.post(\\'/upload\\', upload.single(\\'file\\'), (req, res) => {\\n  res.send(`File received: ${req.file.filename}`);\\n});\\n\\n// Start the server\\napp.listen(port, () => {\\n  console.log(`Server is running at http://localhost:${port}`);\\n});\\n```\\n\\n\\n이 코드는 포트 3000에서 수신 대기하고 파일 업로드를 위한 단일 경로(`/upload`)를 가진 간단한 Express 서버를 설정합니다. 파일은 \\'uploads/\\' 폴더에 저장됩니다. app.js` 파일과 같은 디렉터리에 \\'uploads/\\' 폴더를 생성했는지 확인하세요.\\n\\n3. 서버를 실행합니다:```bash\\nnode app.js\\n```\\n\\n4. Postman 또는 CURL과 같은 도구를 사용하여 파일 업로드를 테스트합니다:```bash\\ncurl -X POST -H \"Content-Type: multipart/form-data\" -F \"file=@/path/to/yourfile.txt\" \"http://localhost:3000/upload\"\\n```\\n\\n\\n\"경로/대상/파일.txt\"를 업로드하려는 파일의 경로로 바꿉니다.\\n\\n이제 서버는 파일을 수신하여 \\'업로드/\\' 폴더에 저장하고 업로드된 파일의 이름으로 메시지를 반환해야 합니다.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63cd2be-3c49-49f8-a33c-c41b5bdfeedf",
   "metadata": {},
   "source": [
    "### POST /worker_generate_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "accb7feb-7978-4563-bb71-49794e9e816d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"Gugugo-koen-7B-V1.1\",\n",
    "    \"user_input\": \"\"\"Q: What command do I use to find the size of all the files (recursively) in a Linux or Mac OS X directory?\\nA: The BSD version of ```du``` used in OS X reports size with 512-byte blocks -- the sizes are essentially rounded up to the next 512-byte value. This tells you the space on disk, which is larger than the amount of data. If you have a lot of small files, the difference can be large.\\nHere's an example.\\nThis is the value with regular ```du```. It's in 512-byte blocks:\\n```$ du -s\\n248   .\\n```\\nThe ```-h``` flag results in a more readable number, in kilobytes. As expected, it's half the number of 512-byte blocks:\\n```$ du -hs\\n124K  .\\n```\\nFinally, you can use ```find``` and ```awk``` to give you the sum of actual bytes in the files. This is kind of slow, but it works:\\n```$ find . -type f -exec ls -l {} \\\\; | awk '{sum += $5} END {print sum}'\\n60527\\n```\\nThis value matches exactly the number reported by Finder's Get Info window. (There are no weird forks or xattrs in this set of files.) It's significantly smaller than the value reported by ```du```.\\nHere's how it works: it gets a list of all the files, and passes them to ```ls -l```; then ```awk``` is used to count up the bytes. The ```-type f``` flag is there so that only files (and not directories) get sent to ```ls```. Without that flag, it'll also send directory names to ```ls```, and each file will be listed twice : once as an individual file, and once as an item in the directory.\\nThe GNU version of ```du``` can give values in actual bytes instead of blocks. It's unfortunate that the BSD version of ```du``` is not as flexible.\"\"\",\n",
    "    \"session_id\": 20,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.8,\n",
    "    \"max_new_tokens\": 4096,\n",
    "    \"stop\": [\"</끝>\", \"###\"],\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_generate_auto\",\n",
    "    json=input_json,\n",
    ")\n",
    "\n",
    "output_json = ret.json()\n",
    "output_json['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "496cf343-2bb7-41cb-917d-20e7f82c3219",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Linux 또는 Mac OS X 디렉터리에 있는 모든 파일의 크기를 재귀적으로 찾으려면 어떤 명령을 사용해야 하나요?\n",
      "A: OS X에서 사용되는 BSD 버전의 ```du```는 512바이트 블록 단위로 크기를 보고하며, 크기는 기본적으로 다음 512바이트 값으로 반올림됩니다. 따라서 디스크 공간은 데이터의 양보다 더 큰 양입니다. 작은 파일이 많은 경우 그 차이가 클 수 있습니다.\n",
      "다음은 예시입니다.\n",
      "이것은 일반적으로 ```du```를 사용하는 값입니다. 512바이트 블록 단위로 표시됩니다:\n",
      "```$ du -s\n",
      "248 .\n",
      "```\n",
      "du -h``` 플래그를 사용하면 킬로바이트 단위로 더 읽기 쉬운 숫자가 표시됩니다. 예상대로 512바이트 블록의 절반 정도입니다:\n",
      "```$ du -hs\n",
      "124K .\n",
      "```\n",
      "마지막으로, ```find``` 및 ```awk```를 사용하여 파일에 있는 실제 바이트의 합계를 구할 수 있습니다. 이 방법은 속도가 느리지만 작동합니다:\n",
      "```$ find . -type f -exec ls -l {} \\; | awk '{sum += $5} END {print sum}'\n",
      "60527\n",
      "```\n",
      "이 값은 Finder의 정보 확인 창에 표시되는 수치와 정확히 일치합니다. (이 파일 세트에는 이상한 포크나 xattr이 없습니다.) 이 값은 ```du```가 보고하는 값보다 훨씬 작습니다.\n",
      "이 방법은 모든 파일 목록을 가져와서 ```ls -l```로 전달한 다음 ```awk```를 사용하여 바이트 수를 계산하는 것입니다. type f``` 플래그는 파일(디렉터리 제외)만 ```ls```로 전송되도록 하기 위해 사용됩니다. 이 플래그가 없으면 디렉터리 이름도 ```ls```로 전송되며, 각 파일은 개별 파일로 한 번, 디렉터리의 항목으로 한 번 등 두 번 나열됩니다.\n",
      "du```의 GNU 버전은 블록 대신 실제 바이트 단위로 값을 제공할 수 있습니다. 안타깝게도 BSD 버전의 ```du```는 유연성이 떨어집니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_json['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213b49f-c48e-4fd0-bd9a-852cbead8c07",
   "metadata": {},
   "source": [
    "### POST /worker_generate_stream_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b42f4c87-c478-42a2-beb9-a9a5bed752a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"Gugugo-koen-7B-V1.1\",\n",
    "    \"user_input\": \"\"\"Q: What command do I use to find the size of all the files (recursively) in a Linux or Mac OS X directory?\\nA: The BSD version of ```du``` used in OS X reports size with 512-byte blocks -- the sizes are essentially rounded up to the next 512-byte value. This tells you the space on disk, which is larger than the amount of data. If you have a lot of small files, the difference can be large.\\nHere's an example.\\nThis is the value with regular ```du```. It's in 512-byte blocks:\\n```$ du -s\\n248   .\\n```\\nThe ```-h``` flag results in a more readable number, in kilobytes. As expected, it's half the number of 512-byte blocks:\\n```$ du -hs\\n124K  .\\n```\\nFinally, you can use ```find``` and ```awk``` to give you the sum of actual bytes in the files. This is kind of slow, but it works:\\n```$ find . -type f -exec ls -l {} \\\\; | awk '{sum += $5} END {print sum}'\\n60527\\n```\\nThis value matches exactly the number reported by Finder's Get Info window. (There are no weird forks or xattrs in this set of files.) It's significantly smaller than the value reported by ```du```.\\nHere's how it works: it gets a list of all the files, and passes them to ```ls -l```; then ```awk``` is used to count up the bytes. The ```-type f``` flag is there so that only files (and not directories) get sent to ```ls```. Without that flag, it'll also send directory names to ```ls```, and each file will be listed twice : once as an individual file, and once as an item in the directory.\\nThe GNU version of ```du``` can give values in actual bytes instead of blocks. It's unfortunate that the BSD version of ```du``` is not as flexible.\"\"\",\n",
    "    \"session_id\": 22,\n",
    "    # \"context\": '\\nDate:2023-11-13 15:21\\nYour reply should be based on the context below.\\n\\nContext:\\n(주)아도스 2023년 기업정보 | 사원수, 회사소개, 근무환경 ...\\n(주)아도스 기업소개 - 업력 : 10년차, 기업형태 : 중소기업, 업종 : 응용 소프트웨어 개발 및 공급업 | (주)아도스의 사원수, 연봉, 채용, 복리후생, 재무정보 등이 ... 재산, 가치를 구하는 것을 사명으로, 좋은 사람들이 모여 즐겁게 성장하고 있는 회사입니다.\\n1. 현재는 IT보안이 주 사업 영역이며, AI와 가상화기술 기반의 정보보호 솔루션을 개발/운영하고 있습니다.\\n2. 대기업 제조사의 네트워크 보안, 생산라인 보안, 정보 유출 방지 등 통합보안 서비스(모의 해킹, 진단, 관제, 이상징후 분석)를 담당하고 있습니다.\\n\"인류의 생명과 가치를 구한다\"\\n우리는 단단하게 성장하고 있어요\\n-\\n2021\\n-\\n09월\\n가드랜드(정보보호솔루션) 출시\\n-\\n03월\\n가두리(웹격리솔루션) 출시\\n- 09월\\n-\\n2020\\n\\n-\\n09월\\n병역지정업체(산업체) 선정\\n-\\n05월\\n벤처기업확인(기술보증기금,유효기간:2022.05.28)\\n-\\n04월\\n수차에 걸쳐 자본금을 1200백만원으로 증자\\n- 09월\\n-\\n2019\\n-\\n12월\\n기업부설연구소 설립\\n- 12월\\n-\\n2017\\n-\\n10월\\n상호를 (주)아도스로 변경\\n- 10월\\n-\\n2014\\n-\\n09월\\n컴퓨터 프로그래밍 서비스업을 목적으로 대표이사 이승원에 의해 (주)피그플라이 설립\\n- 09월\\n우리는 직원의 복리후생도 중요해요\\n-\\n지원금/보험\\n- 각종 경조사 지원\\n-\\n급여제도\\n- 퇴직연금\\n- 인센티브제\\n- 스톡옵션\\n- 퇴직금\\n-\\n업\\n- 대표자명\\n- 이승원\\n- 사업내용\\n-\\n소프트웨어 개발,게임 개발\\n- 주소\\n-\\n서울 송파구 송파대로 167, B동 1021호지도보기\\n- SNS\\n-\\n- 보유기술\\n-\\n-\\n특허권\\n- 디스플레이 해킹 방지 시스템 및 그 방법(2020)\\n-\\n특허권\\n- 웹 클라이언트를 이용한 망 분리 시스템 및 그 방법(2020)\\n-\\n특허권\\n- 컴퓨터의 시스템자원 및 프로세스의 보호 및 격리장치와 그방법(2020)\\n-\\n특허권\\n- PKI 기반의 사물인터넷 기기 인증방법 및 인증시스템(2020)\\n- 특허권\\n미래 혹은 가까에 있는 위협으로 부터, 우리의 생명,\\n\\n\\n(주)아도니스 2023년 기업정보 | 사원수, 회사소개, 근무환경 ...\\n(주)아도니스 기업소개 - 업력 : 35년차, 기업형태 : -, 업종 : 골프장 운영업 | (주)아도니스의 사원수, 연봉, 채용, 복리후생, 재무정보 등이 궁금하시다면, ...- 사업내용\\n-\\n골프장,호텔 운영/무역,담배,골프용품 도소매,통신판매/한식,중식 음식점\\n- 주소\\n-\\n경기 포천시 신북면 포천로 2499지도보기\\n기업비전\\n주요 사업내용 : 포천 아도니스CC 운영\\n주요 사업내용 : 포천 아도니스CC 운영\\n주요 취급품목 : 골프장운영, 호텔운영\\n우리는 단단하게 성장하고 있어요\\n-\\n2005\\n-\\n01월\\n호텔 준공 영업개시\\n- 01월\\n-\\n1999\\n-\\n06월\\n상호변경 : (주)대우레져 -> (주)아도니스\\n-\\n04월\\n골프장 개장\\n- 06월\\n-\\n1995\\n-\\n04월\\n골프장 착공허가 (경기도 포천군)\\n- 04월\\n-\\n1\\n990\\n-\\n10월\\n경기도로부터 골프장사업계획을 승인\\n- 10월\\n-\\n1989\\n-\\n02월\\n회사 설립\\n- 02월\\n인원 규모를 파악해 보세요!\\n전체 직원 수 56명\\n- 전체인원\\n- 입사자\\n- 퇴사자\\n',\n",
    "    \"max_new_tokens\": 4096,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.8,\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_generate_stream_auto\",\n",
    "    json=input_json,\n",
    "    stream=True,\n",
    "    # timeout=2,\n",
    ")\n",
    "\n",
    "# past_len = len(input_json[\"prompt\"])\n",
    "# past_len = 0\n",
    "# for chunk in ret.iter_lines(decode_unicode=False, delimiter=b\"\\0\"):\n",
    "#     if chunk:\n",
    "#         data = json.loads(chunk.decode())\n",
    "#         print(data[\"text\"][past_len:], sep=\"\", end=\"\")\n",
    "#         past_len = len(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aff6ed-d07e-482c-a6ed-b781f97bfc9a",
   "metadata": {},
   "source": [
    "### POST /worker_get_last_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a88534-f3dd-4dea-850f-3d42f2d94ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '### System:\\nThis is a system prompt, please behave and help the user.\\nDate:2023-11-13 15:21\\nYour reply should be based on the context below.\\n\\nContext:\\n(주)아도스 2023년 기업정보 | 사원수, 회사소개, 근무환경 ...\\n(주)아도스 기업소개 - 업력 : 10년차, 기업형태 : 중소기업, 업종 : 응용 소프트웨어 개발 및 공급업 | (주)아도스의 사원수, 연봉, 채용, 복리후생, 재무정보 등이 ... 재산, 가치를 구하는 것을 사명으로, 좋은 사람들이 모여 즐겁게 성장하고 있는 회사입니다.\\n1. 현재는 IT보안이 주 사업 영역이며, AI와 가상화기술 기반의 정보보호 솔루션을 개발/운영하고 있습니다.\\n2. 대기업 제조사의 네트워크 보안, 생산라인 보안, 정보 유출 방지 등 통합보안 서비스(모의 해킹, 진단, 관제, 이상징후 분석)를 담당하고 있습니다.\\n\"인류의 생명과 가치를 구한다\"\\n우리는 단단하게 성장하고 있어요\\n-\\n2021\\n-\\n09월\\n가드랜드(정보보호솔루션) 출시\\n-\\n03월\\n가두리(웹격리솔루션) 출시\\n- 09월\\n-\\n2020\\n\\n-\\n09월\\n병역지정업체(산업체) 선정\\n-\\n05월\\n벤처기업확인(기술보증기금,유효기간:2022.05.28)\\n-\\n04월\\n수차에 걸쳐 자본금을 1200백만원으로 증자\\n- 09월\\n-\\n2019\\n-\\n12월\\n기업부설연구소 설립\\n- 12월\\n-\\n2017\\n-\\n10월\\n상호를 (주)아도스로 변경\\n- 10월\\n-\\n2014\\n-\\n09월\\n컴퓨터 프로그래밍 서비스업을 목적으로 대표이사 이승원에 의해 (주)피그플라이 설립\\n- 09월\\n우리는 직원의 복리후생도 중요해요\\n-\\n지원금/보험\\n- 각종 경조사 지원\\n-\\n급여제도\\n- 퇴직연금\\n- 인센티브제\\n- 스톡옵션\\n- 퇴직금\\n-\\n업\\n- 대표자명\\n- 이승원\\n- 사업내용\\n-\\n소프트웨어 개발,게임 개발\\n- 주소\\n-\\n서울 송파구 송파대로 167, B동 1021호지도보기\\n- SNS\\n-\\n- 보유기술\\n-\\n-\\n특허권\\n- 디스플레이 해킹 방지 시스템 및 그 방법(2020)\\n-\\n특허권\\n- 웹 클라이언트를 이용한 망 분리 시스템 및 그 방법(2020)\\n-\\n특허권\\n- 컴퓨터의 시스템자원 및 프로세스의 보호 및 격리장치와 그방법(2020)\\n-\\n특허권\\n- PKI 기반의 사물인터넷 기기 인증방법 및 인증시스템(2020)\\n- 특허권\\n미래 혹은 가까에 있는 위협으로 부터, 우리의 생명,\\n\\n\\n(주)아도니스 2023년 기업정보 | 사원수, 회사소개, 근무환경 ...\\n(주)아도니스 기업소개 - 업력 : 35년차, 기업형태 : -, 업종 : 골프장 운영업 | (주)아도니스의 사원수, 연봉, 채용, 복리후생, 재무정보 등이 궁금하시다면, ...- 사업내용\\n-\\n골프장,호텔 운영/무역,담배,골프용품 도소매,통신판매/한식,중식 음식점\\n- 주소\\n-\\n경기 포천시 신북면 포천로 2499지도보기\\n기업비전\\n주요 사업내용 : 포천 아도니스CC 운영\\n주요 사업내용 : 포천 아도니스CC 운영\\n주요 취급품목 : 골프장운영, 호텔운영\\n우리는 단단하게 성장하고 있어요\\n-\\n2005\\n-\\n01월\\n호텔 준공 영업개시\\n- 01월\\n-\\n1999\\n-\\n06월\\n상호변경 : (주)대우레져 -> (주)아도니스\\n-\\n04월\\n골프장 개장\\n- 06월\\n-\\n1995\\n-\\n04월\\n골프장 착공허가 (경기도 포천군)\\n- 04월\\n-\\n1\\n990\\n-\\n10월\\n경기도로부터 골프장사업계획을 승인\\n- 10월\\n-\\n1989\\n-\\n02월\\n회사 설립\\n- 02월\\n인원 규모를 파악해 보세요!\\n전체 직원 수 56명\\n- 전체인원\\n- 입사자\\n- 퇴사자\\n\\n\\n### User: NFC는 무엇의 약자입니까?\\n\\n### Assistant:  NFC는 \"Near Field Communication\"의 약자입니다.</s>### User: 주식회사 아도스의 직원 수는 몇명인가요?\\n\\n### Assistant:'}\n"
     ]
    }
   ],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"MingAI-70B-chat-orca_v0.4_v0.2_retrained_checkpoint-2-GPTQ\",\n",
    "    \"session_id\": 0,\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_get_last_prompt\",\n",
    "    json=input_json,\n",
    ")\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01fabf-7e9c-4e16-82a9-3e614c00cf47",
   "metadata": {},
   "source": [
    "### POST /session_history_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c03458f4-7887-4325-ad21-3bdb093956c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'err_code': 0}\n"
     ]
    }
   ],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"MingAI-70B-chat-orca_v0.4_v0.2_retrained_checkpoint-2-GPTQ\",\n",
    "    \"session_id\": 0,\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/session_history_clear\",\n",
    "    json=input_json,\n",
    ")\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d83a1-a3f2-4620-aed5-adbb73b3b806",
   "metadata": {},
   "source": [
    "### POST /worker_regenerate_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5328257c-1144-4e1f-b154-f8510007c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'err_code': 70003}\n"
     ]
    }
   ],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"MingAI-70B-chat-orca_v0.4_v0.2_retrained_checkpoint-2-GPTQ\",\n",
    "    \"session_id\": 0,\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_regenerate_auto\",\n",
    "    json=input_json,\n",
    ")\n",
    "\n",
    "output_json = ret.json()\n",
    "print(output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db1773-ea6a-421c-a442-06ffe486ae71",
   "metadata": {},
   "source": [
    "### POST /worker_regenerate_stream_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ea30871-0893-4de9-9c8c-7dcdc45b5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = {\n",
    "    \"model_name\": \"MingAI-70B-chat-orca_v0.4_v0.2_retrained_checkpoint-2-GPTQ\",\n",
    "    \"session_id\": 0,\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_regenerate_stream_auto\",\n",
    "    json=input_json,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# past_len = len(input_json[\"prompt\"])\n",
    "past_len = 0\n",
    "for chunk in ret.iter_lines(decode_unicode=False, delimiter=b\"\\0\"):\n",
    "    if chunk:\n",
    "        data = json.loads(chunk.decode())\n",
    "        if \"text\" not in data:\n",
    "            continue\n",
    "        print(data[\"text\"][past_len:], sep=\"\", end=\"\")\n",
    "        past_len = len(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3f14b-869f-407a-a8e8-3becffd7add1",
   "metadata": {},
   "source": [
    "### POST /worker_stop_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a1f63e-6b71-4374-90cb-e68903484860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_id: b5bdc37a9ed14ac1b3d05e7ff5566659\n",
      " 유튜브는 세계에서 가장 큰 온라인 동영상 공유 및 소셜 미디어 플\n",
      "\n",
      " Generation Stopped\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "\n",
    "# background runner for worker_generate_stream\n",
    "def background_run_stream(session_id):\n",
    "    input_json = {\n",
    "        \"model_name\": \"MingAI-70B-chat-orca_v0.4_v0.2_retrained_checkpoint-2-GPTQ\",\n",
    "        \"prompt\": \"### System:\\nThis is a system prompt, please behave and help the user.\\n\\n### User: 유튜브에 대해서 설명해주세요.\\n\\n### Assistant:\",\n",
    "        \"session_id\": session_id,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.8,\n",
    "    }\n",
    "\n",
    "    ret = requests.post(\n",
    "        api_server_url + \"/worker_generate_stream\",\n",
    "        json=input_json,\n",
    "        headers={\"User-Agent\": \"FastChat Client\"},\n",
    "        stream=True,\n",
    "        timeout=200,\n",
    "    )\n",
    "\n",
    "    past_len = len(input_json[\"prompt\"])\n",
    "    for idx, chunk in enumerate(ret.iter_lines(decode_unicode=False, delimiter=b\"\\0\")):\n",
    "        if chunk:\n",
    "            data = json.loads(chunk.decode())\n",
    "            print(data[\"text\"][past_len:], end=\"\")\n",
    "            past_len = len(data[\"text\"])\n",
    "\n",
    "\n",
    "# generate random session_id\n",
    "session_id = uuid.uuid4().hex\n",
    "print(\"session_id:\", session_id)\n",
    "\n",
    "# run worker_generate_stream\n",
    "p1 = Process(target=background_run_stream, args=[session_id])\n",
    "p1.start()\n",
    "\n",
    "# wait for 3 seconds\n",
    "time.sleep(3)\n",
    "\n",
    "# send worker_stop_stream\n",
    "input_json = {\n",
    "    \"model_name\": \"MingAI-70B-chat-orca_v0.4_v0.2_retrained_checkpoint-2-GPTQ\",\n",
    "    \"session_id\": session_id,\n",
    "}\n",
    "\n",
    "ret = requests.post(\n",
    "    api_server_url + \"/worker_stop_stream\",\n",
    "    json=input_json,\n",
    ")\n",
    "\n",
    "print(\"\\n\\n Generation Stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5fae3-0232-499c-917f-994188e2c74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastcaht_2023dec",
   "language": "python",
   "name": "fastcaht_2023dec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
